{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'annotations'\n",
    "dataset_name = 'nwpu'\n",
    "merged_file = 'all_labels_nwpu.json'\n",
    "flag_write_files = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will read a `json` file that contains a dictionary of image names and its annotations. Then, it will iterate over each pair and create a new `json` file with the same name as the image and respectively annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file annotations/all_labels_nwpu.json could not be found.\n"
     ]
    }
   ],
   "source": [
    "s2cloudless_annotation_file_path = os.path.join(base_folder, merged_file)\n",
    "flag_file_exists = os.path.exists(s2cloudless_annotation_file_path)\n",
    "if flag_file_exists:\n",
    "    annotations = json.load(open(s2cloudless_annotation_file_path))\n",
    "    for image_name, annotation in annotations.items():\n",
    "        image_name_without_extension = image_name.split('.')[0]\n",
    "        annotation_file_name = f'{image_name_without_extension}.json'\n",
    "        annotation_file_path = os.path.join(base_folder, dataset_name, annotation_file_name)\n",
    "        if flag_write_files:\n",
    "            with open(annotation_file_path, 'w') as outfile:\n",
    "                annotation_pair = {image_name: annotation}\n",
    "                json.dump(annotation_pair, outfile)\n",
    "else:\n",
    "    print(f'file {s2cloudless_annotation_file_path} could not be found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if there are missing labels in the NWPU dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations= [f'lake_{i:03d}.json' for i in range(1, 701)]\n",
    "expected_annotations = set(all_annotations)\n",
    "assert len(expected_annotations) == 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_query = os.path.join(base_folder, dataset_name, '*.json')\n",
    "annotations = set()\n",
    "all_annotation_file_paths = glob.glob(annotations_query)\n",
    "for annotation_file_path in all_annotation_file_paths:\n",
    "    annotation_file_name = annotation_file_path.split(os.sep)[-1]\n",
    "    annotations.add(annotation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "['lake_351.json',\n",
      " 'lake_352.json',\n",
      " 'lake_353.json',\n",
      " 'lake_354.json',\n",
      " 'lake_355.json',\n",
      " 'lake_356.json',\n",
      " 'lake_357.json',\n",
      " 'lake_358.json',\n",
      " 'lake_359.json',\n",
      " 'lake_360.json',\n",
      " 'lake_361.json',\n",
      " 'lake_362.json',\n",
      " 'lake_363.json',\n",
      " 'lake_364.json',\n",
      " 'lake_365.json',\n",
      " 'lake_366.json',\n",
      " 'lake_367.json',\n",
      " 'lake_368.json',\n",
      " 'lake_369.json',\n",
      " 'lake_370.json',\n",
      " 'lake_371.json',\n",
      " 'lake_372.json',\n",
      " 'lake_373.json',\n",
      " 'lake_374.json',\n",
      " 'lake_375.json',\n",
      " 'lake_626.json',\n",
      " 'lake_627.json',\n",
      " 'lake_628.json',\n",
      " 'lake_629.json',\n",
      " 'lake_630.json',\n",
      " 'lake_631.json',\n",
      " 'lake_632.json',\n",
      " 'lake_633.json',\n",
      " 'lake_634.json',\n",
      " 'lake_635.json',\n",
      " 'lake_636.json',\n",
      " 'lake_637.json',\n",
      " 'lake_638.json',\n",
      " 'lake_639.json',\n",
      " 'lake_640.json',\n",
      " 'lake_641.json',\n",
      " 'lake_643.json',\n",
      " 'lake_644.json',\n",
      " 'lake_645.json',\n",
      " 'lake_646.json',\n",
      " 'lake_647.json',\n",
      " 'lake_649.json',\n",
      " 'lake_659.json']\n"
     ]
    }
   ],
   "source": [
    "missing_annotations = expected_annotations - annotations\n",
    "print(len(missing_annotations))\n",
    "pprint.pprint(sorted(missing_annotations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
